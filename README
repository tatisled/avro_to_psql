The module beam_jobs_for_gcp contains several jobs to run directly or or run by DataflowRunner in google cloud platform.

Jobs:
        1. AvroToBQ

The job is aim to read avro file from gcp storage, apply some transformation due to apache calcite driver and write the complete result to the
target gcp Big Query table.

To run this job directly use following argument:
--runner=DirectRunner
--project=onboardingproject-319313
--stagingLocation=gs://onboardingproject_bucket_1/staging
--region=us-central1
--appName=AvroToBQCalcite
--gcsTempLocation=gs://onboardingproject_bucket_1/tmp
--bqTable=onboardingproject-319313:bq_dataset.bq_table_with_transform
--inputPath=gs://onboardingproject_bucket_1/avro_dataset.avro

To run this job by gcp DataflowRunner use following arguments:
--runner=DataflowRunner
--project=onboardingproject-319313
--stagingLocation=gs://onboardingproject_bucket_1/staging
--region=us-central1
--appName=AvroToBQCalcite
--gcsTempLocation=gs://onboardingproject_bucket_1/tmp
--bqTable=onboardingproject-319313:bq_dataset.bq_table_with_transform
--inputPath=gs://onboardingproject_bucket_1/avro_dataset.avro

To create Dataflow template for this job use following terminal command:
mvn compile exec:java \
     -Dexec.mainClass=com.github.tatisled.phase2.AvroToBQ \
     -Dexec.cleanupDaemonThreads=false \
     -Dexec.args="--runner=DataflowRunner \
                  --project=onboardingproject-319313 \
                  --stagingLocation=gs://onboardingproject_bucket_1/staging \
                  --region=us-central1 \
                  --appName=AvroToBQCalcite \
                  --gcsTempLocation=gs://onboardingproject_bucket_1/tmp \
                  --templateLocation=gs://onboardingproject_bucket_1/custom_templates/avro_to_bq_with_calcite_template.json"

        2. AvroToPsql

The job is aim to read avro file from gcp storage and write data as is into Postgres instance of gcp.

To run this job directly use following argument:
--runner=direct
--project=onboardingproject-319313
--stagingLocation=gs://onboardingproject_bucket_1/staging
--region=us-central1
--appName=AvroToPsql
--tempLocation=gs://onboardingproject_bucket_1/tmp
--inputPath=gs://onboardingproject_bucket_1/avro_dataset.avro

To run this job by gcp DataflowRunner use following arguments:
--runner=DataflowRunner
--project=onboardingproject-319313
--stagingLocation=gs://onboardingproject_bucket_1/staging
--region=us-central1
--appName=AvroToPsql
--tempLocation=gs://onboardingproject_bucket_1/tmp
--inputPath=gs://onboardingproject_bucket_1/avro_dataset.avro

To create Dataflow template for this job use following terminal command:
mvn compile exec:java \
     -Dexec.mainClass=com.github.tatisled.phase2.AvroToPsql \
     -Dexec.cleanupDaemonThreads=false \
     -Dexec.args="--runner=DataflowRunner \
                  --project=onboardingproject-319313 \
                  --stagingLocation=gs://onboardingproject_bucket_1/staging \
                  --region=us-central1 \
                  --appName=AvroToPsql \
                  --tempLocation=gs://onboardingproject_bucket_1/tmp \
                  --templateLocation=gs://onboardingproject_bucket_1/custom_templates/avro_to_psql_template.json"

        3. PsqlToAvro

The job is aim to read data from Postgres instance of gcp and write it as is into avro file in gcp storage.

To run this job directly use following argument:
--runner=DirectRunner
--project=onboardingproject-319313
--stagingLocation=gs://onboardingproject_bucket_1/staging
--region=us-central1
--appName=PsqlToAvro
--tempLocation=gs://onboardingproject_bucket_1/tmp
--avroFileName=avro_output
--bucketName=gs://onboardingproject_bucket_2

To run this job by gcp DataflowRunner use following arguments:
--runner=DataflowRunner
--project=onboardingproject-319313
--stagingLocation=gs://onboardingproject_bucket_1/staging
--region=us-central1
--appName=PsqlToAvro
--tempLocation=gs://onboardingproject_bucket_1/tmp
--avroFileName=avro_output
--bucketName=gs://onboardingproject_bucket_2

To create Dataflow template for this job use following terminal command:
mvn compile exec:java \
     -Dexec.mainClass=com.github.tatisled.phase2.PsqlToAvro \
     -Dexec.cleanupDaemonThreads=false \
     -Dexec.args="--runner=DataflowRunner \
                  --project=onboardingproject-319313 \
                  --stagingLocation=gs://onboardingproject_bucket_1/staging \
                  --region=us-central1 \
                  --appName=PsqlToAvro \
                  --tempLocation=gs://onboardingproject_bucket_1/tmp \
                  --gcpTempLocation=gs://onboardingproject_bucket_1/gcp_tmp \
                  --templateLocation=gs://onboardingproject_bucket_1/custom_templates/psql_to_avro_template.json"

gcloud alpha monitoring policies create --policy-from-file="alertpolicy/metric_threshold_policy.json"

        4. PubSubToBQ
To create Dataflow template for this job use following terminal command:
mvn compile exec:java \
     -Dexec.mainClass=com.github.tatisled.phase5.PubSubToBQ \
     -Dexec.cleanupDaemonThreads=false \
     -Dexec.args="--runner=DataflowRunner \
                  --project=onboardingproject-319313 \
                  --stagingLocation=gs://onboardingproject_bucket_1/staging \
                  --region=us-central1 \
                  --appName=PubSubToBq-1234 \
                  --tempLocation=gs://onboardingproject_bucket_1/tmp \
                  --templateLocation=gs://onboardingproject_bucket_1/custom_templates/pubsub_to_bq_template.json"

